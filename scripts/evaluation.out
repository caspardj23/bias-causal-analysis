{'Professions': 0.8390397481306572, 'model': 'gpt2_baseline', 'seed': '0'}
{'LM Score': 93.27790824312564, 'SS Score': 62.66777425473077, 'ICAT': 69.64543855157751, 'BLiMP': 0.7969, 'BLiMP AGA': 0.955, 'BLiMP ISV1': 0.894, 'BLiMP ISV2': 0.858, 'BLiMP RSV1': 0.892, 'BLiMP RSV2': 0.948, 'CrowS-Pairs': 0.578125, 'WinoBias Type1 Dev': 0.5681818181818182, 'WinoBias Type1 Test': 0.5707070707070707, 'WinoBias Type2 Dev': 0.6287878787878788, 'WinoBias Type2 Test': 0.6237373737373737, 'model': 'gpt2_baseline', 'seed': '0'}
{'LM Score': 93.27790824312564, 'SS Score': 62.66777425473077, 'ICAT': 69.64543855157751, 'BLiMP': 0.7969, 'BLiMP AGA': 0.955, 'BLiMP ISV1': 0.894, 'BLiMP ISV2': 0.858, 'BLiMP RSV1': 0.892, 'BLiMP RSV2': 0.948, 'CrowS-Pairs': 0.578125, 'WinoBias Type1 Dev': 0.5681818181818182, 'WinoBias Type1 Test': 0.5707070707070707, 'WinoBias Type2 Dev': 0.6287878787878788, 'WinoBias Type2 Test': 0.6237373737373737, 'model': 'gpt2_baseline', 'seed': '0', 'Professions': 0.8390397481306572}
{'Professions': 0.8156237701692247, 'model': 'gpt2_attn_heads_dm_top10', 'seed': '4'}
{'LM Score': 87.26991124817212, 'SS Score': 60.8743776352472, 'ICAT': 68.2897918260295, 'BLiMP': 0.7779, 'BLiMP AGA': 0.956, 'BLiMP ISV1': 0.9, 'BLiMP ISV2': 0.866, 'BLiMP RSV1': 0.907, 'BLiMP RSV2': 0.936, 'CrowS-Pairs': 0.55, 'WinoBias Type1 Dev': 0.5934343434343434, 'WinoBias Type1 Test': 0.5707070707070707, 'WinoBias Type2 Dev': 0.6111111111111112, 'WinoBias Type2 Test': 0.6464646464646465, 'model': 'gpt2_attn_heads_dm_top10', 'seed': '4'}
{'LM Score': 87.26991124817212, 'SS Score': 60.8743776352472, 'ICAT': 68.2897918260295, 'BLiMP': 0.7779, 'BLiMP AGA': 0.956, 'BLiMP ISV1': 0.9, 'BLiMP ISV2': 0.866, 'BLiMP RSV1': 0.907, 'BLiMP RSV2': 0.936, 'CrowS-Pairs': 0.55, 'WinoBias Type1 Dev': 0.5934343434343434, 'WinoBias Type1 Test': 0.5707070707070707, 'WinoBias Type2 Dev': 0.6111111111111112, 'WinoBias Type2 Test': 0.6464646464646465, 'model': 'gpt2_attn_heads_dm_top10', 'seed': '4', 'Professions': 0.8156237701692247}
{'Professions': 0.829004329004329, 'model': 'gpt2_random', 'seed': '4'}
{'LM Score': 87.23764407894842, 'SS Score': 61.67809726505378, 'ICAT': 66.86225022438637, 'BLiMP': 0.7732, 'BLiMP AGA': 0.951, 'BLiMP ISV1': 0.885, 'BLiMP ISV2': 0.865, 'BLiMP RSV1': 0.892, 'BLiMP RSV2': 0.913, 'CrowS-Pairs': 0.571875, 'WinoBias Type1 Dev': 0.6035353535353535, 'WinoBias Type1 Test': 0.5505050505050505, 'WinoBias Type2 Dev': 0.6212121212121212, 'WinoBias Type2 Test': 0.6186868686868687, 'model': 'gpt2_random', 'seed': '4'}
{'LM Score': 87.23764407894842, 'SS Score': 61.67809726505378, 'ICAT': 66.86225022438637, 'BLiMP': 0.7732, 'BLiMP AGA': 0.951, 'BLiMP ISV1': 0.885, 'BLiMP ISV2': 0.865, 'BLiMP RSV1': 0.892, 'BLiMP RSV2': 0.913, 'CrowS-Pairs': 0.571875, 'WinoBias Type1 Dev': 0.6035353535353535, 'WinoBias Type1 Test': 0.5505050505050505, 'WinoBias Type2 Dev': 0.6212121212121212, 'WinoBias Type2 Test': 0.6186868686868687, 'model': 'gpt2_random', 'seed': '4', 'Professions': 0.829004329004329}
{'Professions': 0.8097205824478552, 'model': 'gpt2_random', 'seed': '1'}
{'LM Score': 87.95986630117065, 'SS Score': 63.64991691078647, 'ICAT': 63.946968971273314, 'BLiMP': 0.7691, 'BLiMP AGA': 0.956, 'BLiMP ISV1': 0.888, 'BLiMP ISV2': 0.868, 'BLiMP RSV1': 0.897, 'BLiMP RSV2': 0.92, 'CrowS-Pairs': 0.58125, 'WinoBias Type1 Dev': 0.601010101010101, 'WinoBias Type1 Test': 0.5429292929292929, 'WinoBias Type2 Dev': 0.5883838383838383, 'WinoBias Type2 Test': 0.6186868686868687, 'model': 'gpt2_random', 'seed': '1'}
{'LM Score': 87.95986630117065, 'SS Score': 63.64991691078647, 'ICAT': 63.946968971273314, 'BLiMP': 0.7691, 'BLiMP AGA': 0.956, 'BLiMP ISV1': 0.888, 'BLiMP ISV2': 0.868, 'BLiMP RSV1': 0.897, 'BLiMP RSV2': 0.92, 'CrowS-Pairs': 0.58125, 'WinoBias Type1 Dev': 0.601010101010101, 'WinoBias Type1 Test': 0.5429292929292929, 'WinoBias Type2 Dev': 0.5883838383838383, 'WinoBias Type2 Test': 0.6186868686868687, 'model': 'gpt2_random', 'seed': '1', 'Professions': 0.8097205824478552}
{'Professions': 0.8164108618654073, 'model': 'gpt2_attn_heads_acdc', 'seed': '4'}
{'LM Score': 86.89184857010945, 'SS Score': 61.76967235662888, 'ICAT': 66.43807680746944, 'BLiMP': 0.7729, 'BLiMP AGA': 0.954, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.871, 'BLiMP RSV1': 0.901, 'BLiMP RSV2': 0.925, 'CrowS-Pairs': 0.565625, 'WinoBias Type1 Dev': 0.601010101010101, 'WinoBias Type1 Test': 0.5429292929292929, 'WinoBias Type2 Dev': 0.601010101010101, 'WinoBias Type2 Test': 0.6287878787878788, 'model': 'gpt2_attn_heads_acdc', 'seed': '4'}
{'LM Score': 86.89184857010945, 'SS Score': 61.76967235662888, 'ICAT': 66.43807680746944, 'BLiMP': 0.7729, 'BLiMP AGA': 0.954, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.871, 'BLiMP RSV1': 0.901, 'BLiMP RSV2': 0.925, 'CrowS-Pairs': 0.565625, 'WinoBias Type1 Dev': 0.601010101010101, 'WinoBias Type1 Test': 0.5429292929292929, 'WinoBias Type2 Dev': 0.601010101010101, 'WinoBias Type2 Test': 0.6287878787878788, 'model': 'gpt2_attn_heads_acdc', 'seed': '4', 'Professions': 0.8164108618654073}
{'Professions': 0.849862258953168, 'model': 'gpt2_all', 'seed': '4'}
{'LM Score': 87.87094909920997, 'SS Score': 63.89076125163082, 'ICAT': 63.45906160138336, 'BLiMP': 0.7634, 'BLiMP AGA': 0.965, 'BLiMP ISV1': 0.87, 'BLiMP ISV2': 0.849, 'BLiMP RSV1': 0.907, 'BLiMP RSV2': 0.88, 'CrowS-Pairs': 0.61875, 'WinoBias Type1 Dev': 0.5782828282828283, 'WinoBias Type1 Test': 0.5555555555555556, 'WinoBias Type2 Dev': 0.553030303030303, 'WinoBias Type2 Test': 0.5782828282828283, 'model': 'gpt2_all', 'seed': '4'}
{'LM Score': 87.87094909920997, 'SS Score': 63.89076125163082, 'ICAT': 63.45906160138336, 'BLiMP': 0.7634, 'BLiMP AGA': 0.965, 'BLiMP ISV1': 0.87, 'BLiMP ISV2': 0.849, 'BLiMP RSV1': 0.907, 'BLiMP RSV2': 0.88, 'CrowS-Pairs': 0.61875, 'WinoBias Type1 Dev': 0.5782828282828283, 'WinoBias Type1 Test': 0.5555555555555556, 'WinoBias Type2 Dev': 0.553030303030303, 'WinoBias Type2 Test': 0.5782828282828283, 'model': 'gpt2_all', 'seed': '4', 'Professions': 0.849862258953168}
{'Professions': 0.8376623376623377, 'model': 'gpt2_acdc', 'seed': '5'}
{'LM Score': 87.92401455227541, 'SS Score': 59.5073432203867, 'ICAT': 71.20553887902027, 'BLiMP': 0.7601, 'BLiMP AGA': 0.95, 'BLiMP ISV1': 0.88, 'BLiMP ISV2': 0.863, 'BLiMP RSV1': 0.905, 'BLiMP RSV2': 0.909, 'CrowS-Pairs': 0.59375, 'WinoBias Type1 Dev': 0.5681818181818182, 'WinoBias Type1 Test': 0.5606060606060606, 'WinoBias Type2 Dev': 0.6085858585858586, 'WinoBias Type2 Test': 0.5808080808080808, 'model': 'gpt2_acdc', 'seed': '5'}
{'LM Score': 87.92401455227541, 'SS Score': 59.5073432203867, 'ICAT': 71.20553887902027, 'BLiMP': 0.7601, 'BLiMP AGA': 0.95, 'BLiMP ISV1': 0.88, 'BLiMP ISV2': 0.863, 'BLiMP RSV1': 0.905, 'BLiMP RSV2': 0.909, 'CrowS-Pairs': 0.59375, 'WinoBias Type1 Dev': 0.5681818181818182, 'WinoBias Type1 Test': 0.5606060606060606, 'WinoBias Type2 Dev': 0.6085858585858586, 'WinoBias Type2 Test': 0.5808080808080808, 'model': 'gpt2_acdc', 'seed': '5', 'Professions': 0.8376623376623377}
{'Professions': 0.8138528138528138, 'model': 'gpt2_attn_layers', 'seed': '3'}
{'LM Score': 88.0166515449124, 'SS Score': 63.092333753203306, 'ICAT': 64.9697839876046, 'BLiMP': 0.7686, 'BLiMP AGA': 0.94, 'BLiMP ISV1': 0.897, 'BLiMP ISV2': 0.864, 'BLiMP RSV1': 0.905, 'BLiMP RSV2': 0.942, 'CrowS-Pairs': 0.58125, 'WinoBias Type1 Dev': 0.5833333333333334, 'WinoBias Type1 Test': 0.5580808080808081, 'WinoBias Type2 Dev': 0.6161616161616161, 'WinoBias Type2 Test': 0.5858585858585859, 'model': 'gpt2_attn_layers', 'seed': '3'}
{'LM Score': 88.0166515449124, 'SS Score': 63.092333753203306, 'ICAT': 64.9697839876046, 'BLiMP': 0.7686, 'BLiMP AGA': 0.94, 'BLiMP ISV1': 0.897, 'BLiMP ISV2': 0.864, 'BLiMP RSV1': 0.905, 'BLiMP RSV2': 0.942, 'CrowS-Pairs': 0.58125, 'WinoBias Type1 Dev': 0.5833333333333334, 'WinoBias Type1 Test': 0.5580808080808081, 'WinoBias Type2 Dev': 0.6161616161616161, 'WinoBias Type2 Test': 0.5858585858585859, 'model': 'gpt2_attn_layers', 'seed': '3', 'Professions': 0.8138528138528138}
{'Professions': 0.8364817001180638, 'model': 'gpt2_attn_layers_all', 'seed': '2'}
{'LM Score': 88.00474678300766, 'SS Score': 66.30592756679714, 'ICAT': 59.30476625144673, 'BLiMP': 0.779, 'BLiMP AGA': 0.972, 'BLiMP ISV1': 0.889, 'BLiMP ISV2': 0.854, 'BLiMP RSV1': 0.917, 'BLiMP RSV2': 0.891, 'CrowS-Pairs': 0.578125, 'WinoBias Type1 Dev': 0.5732323232323232, 'WinoBias Type1 Test': 0.5681818181818182, 'WinoBias Type2 Dev': 0.6388888888888888, 'WinoBias Type2 Test': 0.5909090909090909, 'model': 'gpt2_attn_layers_all', 'seed': '2'}
{'LM Score': 88.00474678300766, 'SS Score': 66.30592756679714, 'ICAT': 59.30476625144673, 'BLiMP': 0.779, 'BLiMP AGA': 0.972, 'BLiMP ISV1': 0.889, 'BLiMP ISV2': 0.854, 'BLiMP RSV1': 0.917, 'BLiMP RSV2': 0.891, 'CrowS-Pairs': 0.578125, 'WinoBias Type1 Dev': 0.5732323232323232, 'WinoBias Type1 Test': 0.5681818181818182, 'WinoBias Type2 Dev': 0.6388888888888888, 'WinoBias Type2 Test': 0.5909090909090909, 'model': 'gpt2_attn_layers_all', 'seed': '2', 'Professions': 0.8364817001180638}
{'Professions': 0.8307752853207399, 'model': 'gpt2_attn_heads_acdc', 'seed': '2'}
{'LM Score': 87.47462818984557, 'SS Score': 61.590071924854534, 'ICAT': 67.19788354344121, 'BLiMP': 0.7749, 'BLiMP AGA': 0.957, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.87, 'BLiMP RSV1': 0.903, 'BLiMP RSV2': 0.933, 'CrowS-Pairs': 0.55, 'WinoBias Type1 Dev': 0.5909090909090909, 'WinoBias Type1 Test': 0.553030303030303, 'WinoBias Type2 Dev': 0.5959595959595959, 'WinoBias Type2 Test': 0.6287878787878788, 'model': 'gpt2_attn_heads_acdc', 'seed': '2'}
{'LM Score': 87.47462818984557, 'SS Score': 61.590071924854534, 'ICAT': 67.19788354344121, 'BLiMP': 0.7749, 'BLiMP AGA': 0.957, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.87, 'BLiMP RSV1': 0.903, 'BLiMP RSV2': 0.933, 'CrowS-Pairs': 0.55, 'WinoBias Type1 Dev': 0.5909090909090909, 'WinoBias Type1 Test': 0.553030303030303, 'WinoBias Type2 Dev': 0.5959595959595959, 'WinoBias Type2 Test': 0.6287878787878788, 'model': 'gpt2_attn_heads_acdc', 'seed': '2', 'Professions': 0.8307752853207399}
{'Professions': 0.8315623770169225, 'model': 'gpt2_attn_layers_all', 'seed': '4'}
{'LM Score': 87.54579277405364, 'SS Score': 63.78100321578582, 'ICAT': 63.41641573909858, 'BLiMP': 0.7806, 'BLiMP AGA': 0.969, 'BLiMP ISV1': 0.881, 'BLiMP ISV2': 0.848, 'BLiMP RSV1': 0.909, 'BLiMP RSV2': 0.892, 'CrowS-Pairs': 0.565625, 'WinoBias Type1 Dev': 0.6136363636363636, 'WinoBias Type1 Test': 0.5606060606060606, 'WinoBias Type2 Dev': 0.6414141414141414, 'WinoBias Type2 Test': 0.6515151515151515, 'model': 'gpt2_attn_layers_all', 'seed': '4'}
{'LM Score': 87.54579277405364, 'SS Score': 63.78100321578582, 'ICAT': 63.41641573909858, 'BLiMP': 0.7806, 'BLiMP AGA': 0.969, 'BLiMP ISV1': 0.881, 'BLiMP ISV2': 0.848, 'BLiMP RSV1': 0.909, 'BLiMP RSV2': 0.892, 'CrowS-Pairs': 0.565625, 'WinoBias Type1 Dev': 0.6136363636363636, 'WinoBias Type1 Test': 0.5606060606060606, 'WinoBias Type2 Dev': 0.6414141414141414, 'WinoBias Type2 Test': 0.6515151515151515, 'model': 'gpt2_attn_layers_all', 'seed': '4', 'Professions': 0.8315623770169225}
{'Professions': 0.8327430145611964, 'model': 'gpt2_attn_heads_acdc', 'seed': '5'}
{'LM Score': 86.87373632808416, 'SS Score': 61.56635972722929, 'ICAT': 66.77747862370238, 'BLiMP': 0.7767, 'BLiMP AGA': 0.964, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.87, 'BLiMP RSV1': 0.902, 'BLiMP RSV2': 0.937, 'CrowS-Pairs': 0.553125, 'WinoBias Type1 Dev': 0.5681818181818182, 'WinoBias Type1 Test': 0.5505050505050505, 'WinoBias Type2 Dev': 0.6287878787878788, 'WinoBias Type2 Test': 0.6338383838383839, 'model': 'gpt2_attn_heads_acdc', 'seed': '5'}
{'LM Score': 86.87373632808416, 'SS Score': 61.56635972722929, 'ICAT': 66.77747862370238, 'BLiMP': 0.7767, 'BLiMP AGA': 0.964, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.87, 'BLiMP RSV1': 0.902, 'BLiMP RSV2': 0.937, 'CrowS-Pairs': 0.553125, 'WinoBias Type1 Dev': 0.5681818181818182, 'WinoBias Type1 Test': 0.5505050505050505, 'WinoBias Type2 Dev': 0.6287878787878788, 'WinoBias Type2 Test': 0.6338383838383839, 'model': 'gpt2_attn_heads_acdc', 'seed': '5', 'Professions': 0.8327430145611964}
{'Professions': 0.8305785123966942, 'model': 'gpt2_random', 'seed': '3'}
{'LM Score': 87.82653296783732, 'SS Score': 62.10819936906894, 'ICAT': 66.55810954646371, 'BLiMP': 0.7714, 'BLiMP AGA': 0.954, 'BLiMP ISV1': 0.891, 'BLiMP ISV2': 0.859, 'BLiMP RSV1': 0.895, 'BLiMP RSV2': 0.913, 'CrowS-Pairs': 0.571875, 'WinoBias Type1 Dev': 0.5757575757575758, 'WinoBias Type1 Test': 0.553030303030303, 'WinoBias Type2 Dev': 0.6186868686868687, 'WinoBias Type2 Test': 0.6388888888888888, 'model': 'gpt2_random', 'seed': '3'}
{'LM Score': 87.82653296783732, 'SS Score': 62.10819936906894, 'ICAT': 66.55810954646371, 'BLiMP': 0.7714, 'BLiMP AGA': 0.954, 'BLiMP ISV1': 0.891, 'BLiMP ISV2': 0.859, 'BLiMP RSV1': 0.895, 'BLiMP RSV2': 0.913, 'CrowS-Pairs': 0.571875, 'WinoBias Type1 Dev': 0.5757575757575758, 'WinoBias Type1 Test': 0.553030303030303, 'WinoBias Type2 Dev': 0.6186868686868687, 'WinoBias Type2 Test': 0.6388888888888888, 'model': 'gpt2_random', 'seed': '3', 'Professions': 0.8305785123966942}
{'Professions': 0.8048012593467139, 'model': 'gpt2_all', 'seed': '3'}
{'LM Score': 87.0157474570518, 'SS Score': 60.4904515774081, 'ICAT': 68.75905775364832, 'BLiMP': 0.764, 'BLiMP AGA': 0.967, 'BLiMP ISV1': 0.873, 'BLiMP ISV2': 0.841, 'BLiMP RSV1': 0.912, 'BLiMP RSV2': 0.842, 'CrowS-Pairs': 0.55625, 'WinoBias Type1 Dev': 0.5984848484848485, 'WinoBias Type1 Test': 0.5656565656565656, 'WinoBias Type2 Dev': 0.6161616161616161, 'WinoBias Type2 Test': 0.6085858585858586, 'model': 'gpt2_all', 'seed': '3'}
{'LM Score': 87.0157474570518, 'SS Score': 60.4904515774081, 'ICAT': 68.75905775364832, 'BLiMP': 0.764, 'BLiMP AGA': 0.967, 'BLiMP ISV1': 0.873, 'BLiMP ISV2': 0.841, 'BLiMP RSV1': 0.912, 'BLiMP RSV2': 0.842, 'CrowS-Pairs': 0.55625, 'WinoBias Type1 Dev': 0.5984848484848485, 'WinoBias Type1 Test': 0.5656565656565656, 'WinoBias Type2 Dev': 0.6161616161616161, 'WinoBias Type2 Test': 0.6085858585858586, 'model': 'gpt2_all', 'seed': '3', 'Professions': 0.8048012593467139}
{'Professions': 0.7721369539551358, 'model': 'gpt2_acdc', 'seed': '3'}
{'LM Score': 87.70697659828093, 'SS Score': 61.51724957811914, 'ICAT': 67.5041138137878, 'BLiMP': 0.7613, 'BLiMP AGA': 0.964, 'BLiMP ISV1': 0.887, 'BLiMP ISV2': 0.852, 'BLiMP RSV1': 0.904, 'BLiMP RSV2': 0.871, 'CrowS-Pairs': 0.575, 'WinoBias Type1 Dev': 0.5959595959595959, 'WinoBias Type1 Test': 0.553030303030303, 'WinoBias Type2 Dev': 0.601010101010101, 'WinoBias Type2 Test': 0.6262626262626263, 'model': 'gpt2_acdc', 'seed': '3'}
{'LM Score': 87.70697659828093, 'SS Score': 61.51724957811914, 'ICAT': 67.5041138137878, 'BLiMP': 0.7613, 'BLiMP AGA': 0.964, 'BLiMP ISV1': 0.887, 'BLiMP ISV2': 0.852, 'BLiMP RSV1': 0.904, 'BLiMP RSV2': 0.871, 'CrowS-Pairs': 0.575, 'WinoBias Type1 Dev': 0.5959595959595959, 'WinoBias Type1 Test': 0.553030303030303, 'WinoBias Type2 Dev': 0.601010101010101, 'WinoBias Type2 Test': 0.6262626262626263, 'model': 'gpt2_acdc', 'seed': '3', 'Professions': 0.7721369539551358}
{'Professions': 0.8197560015741834, 'model': 'gpt2_attn_heads_dm_top10', 'seed': '5'}
{'LM Score': 86.23514528949312, 'SS Score': 62.07592423679381, 'ICAT': 65.40776366819661, 'BLiMP': 0.7796, 'BLiMP AGA': 0.961, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.866, 'BLiMP RSV1': 0.902, 'BLiMP RSV2': 0.932, 'CrowS-Pairs': 0.55, 'WinoBias Type1 Dev': 0.553030303030303, 'WinoBias Type1 Test': 0.5808080808080808, 'WinoBias Type2 Dev': 0.6136363636363636, 'WinoBias Type2 Test': 0.6439393939393939, 'model': 'gpt2_attn_heads_dm_top10', 'seed': '5'}
{'LM Score': 86.23514528949312, 'SS Score': 62.07592423679381, 'ICAT': 65.40776366819661, 'BLiMP': 0.7796, 'BLiMP AGA': 0.961, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.866, 'BLiMP RSV1': 0.902, 'BLiMP RSV2': 0.932, 'CrowS-Pairs': 0.55, 'WinoBias Type1 Dev': 0.553030303030303, 'WinoBias Type1 Test': 0.5808080808080808, 'WinoBias Type2 Dev': 0.6136363636363636, 'WinoBias Type2 Test': 0.6439393939393939, 'model': 'gpt2_attn_heads_dm_top10', 'seed': '5', 'Professions': 0.8197560015741834}
{'Professions': 0.8364817001180638, 'model': 'gpt2_all', 'seed': '5'}
{'LM Score': 87.91633889459976, 'SS Score': 59.708042521086, 'ICAT': 70.84642776886012, 'BLiMP': 0.7701, 'BLiMP AGA': 0.965, 'BLiMP ISV1': 0.873, 'BLiMP ISV2': 0.859, 'BLiMP RSV1': 0.927, 'BLiMP RSV2': 0.89, 'CrowS-Pairs': 0.590625, 'WinoBias Type1 Dev': 0.5858585858585859, 'WinoBias Type1 Test': 0.5505050505050505, 'WinoBias Type2 Dev': 0.6060606060606061, 'WinoBias Type2 Test': 0.5984848484848485, 'model': 'gpt2_all', 'seed': '5'}
{'LM Score': 87.91633889459976, 'SS Score': 59.708042521086, 'ICAT': 70.84642776886012, 'BLiMP': 0.7701, 'BLiMP AGA': 0.965, 'BLiMP ISV1': 0.873, 'BLiMP ISV2': 0.859, 'BLiMP RSV1': 0.927, 'BLiMP RSV2': 0.89, 'CrowS-Pairs': 0.590625, 'WinoBias Type1 Dev': 0.5858585858585859, 'WinoBias Type1 Test': 0.5505050505050505, 'WinoBias Type2 Dev': 0.6060606060606061, 'WinoBias Type2 Test': 0.5984848484848485, 'model': 'gpt2_all', 'seed': '5', 'Professions': 0.8364817001180638}
{'Professions': 0.8112947658402204, 'model': 'gpt2_attn_layers', 'seed': '4'}
{'LM Score': 87.3157067570111, 'SS Score': 60.33835809922766, 'ICAT': 69.26168587418843, 'BLiMP': 0.7691, 'BLiMP AGA': 0.945, 'BLiMP ISV1': 0.9, 'BLiMP ISV2': 0.867, 'BLiMP RSV1': 0.904, 'BLiMP RSV2': 0.939, 'CrowS-Pairs': 0.56875, 'WinoBias Type1 Dev': 0.5681818181818182, 'WinoBias Type1 Test': 0.5505050505050505, 'WinoBias Type2 Dev': 0.6161616161616161, 'WinoBias Type2 Test': 0.5959595959595959, 'model': 'gpt2_attn_layers', 'seed': '4'}
{'LM Score': 87.3157067570111, 'SS Score': 60.33835809922766, 'ICAT': 69.26168587418843, 'BLiMP': 0.7691, 'BLiMP AGA': 0.945, 'BLiMP ISV1': 0.9, 'BLiMP ISV2': 0.867, 'BLiMP RSV1': 0.904, 'BLiMP RSV2': 0.939, 'CrowS-Pairs': 0.56875, 'WinoBias Type1 Dev': 0.5681818181818182, 'WinoBias Type1 Test': 0.5505050505050505, 'WinoBias Type2 Dev': 0.6161616161616161, 'WinoBias Type2 Test': 0.5959595959595959, 'model': 'gpt2_attn_layers', 'seed': '4', 'Professions': 0.8112947658402204}
{'Professions': 0.8319559228650137, 'model': 'gpt2_random', 'seed': '5'}
{'LM Score': 86.63658217788652, 'SS Score': 62.46745862832819, 'ICAT': 65.03382209783541, 'BLiMP': 0.7753, 'BLiMP AGA': 0.963, 'BLiMP ISV1': 0.895, 'BLiMP ISV2': 0.86, 'BLiMP RSV1': 0.891, 'BLiMP RSV2': 0.907, 'CrowS-Pairs': 0.58125, 'WinoBias Type1 Dev': 0.5858585858585859, 'WinoBias Type1 Test': 0.5681818181818182, 'WinoBias Type2 Dev': 0.5959595959595959, 'WinoBias Type2 Test': 0.6186868686868687, 'model': 'gpt2_random', 'seed': '5'}
{'LM Score': 86.63658217788652, 'SS Score': 62.46745862832819, 'ICAT': 65.03382209783541, 'BLiMP': 0.7753, 'BLiMP AGA': 0.963, 'BLiMP ISV1': 0.895, 'BLiMP ISV2': 0.86, 'BLiMP RSV1': 0.891, 'BLiMP RSV2': 0.907, 'CrowS-Pairs': 0.58125, 'WinoBias Type1 Dev': 0.5858585858585859, 'WinoBias Type1 Test': 0.5681818181818182, 'WinoBias Type2 Dev': 0.5959595959595959, 'WinoBias Type2 Test': 0.6186868686868687, 'model': 'gpt2_random', 'seed': '5', 'Professions': 0.8319559228650137}
{'Professions': 0.8225108225108225, 'model': 'gpt2_attn_heads_cma_top10', 'seed': '3'}
{'LM Score': 87.82597555423642, 'SS Score': 62.02932269019226, 'ICAT': 66.6962355437795, 'BLiMP': 0.7697, 'BLiMP AGA': 0.952, 'BLiMP ISV1': 0.895, 'BLiMP ISV2': 0.865, 'BLiMP RSV1': 0.896, 'BLiMP RSV2': 0.936, 'CrowS-Pairs': 0.553125, 'WinoBias Type1 Dev': 0.5732323232323232, 'WinoBias Type1 Test': 0.5631313131313131, 'WinoBias Type2 Dev': 0.5909090909090909, 'WinoBias Type2 Test': 0.6287878787878788, 'model': 'gpt2_attn_heads_cma_top10', 'seed': '3'}
{'LM Score': 87.82597555423642, 'SS Score': 62.02932269019226, 'ICAT': 66.6962355437795, 'BLiMP': 0.7697, 'BLiMP AGA': 0.952, 'BLiMP ISV1': 0.895, 'BLiMP ISV2': 0.865, 'BLiMP RSV1': 0.896, 'BLiMP RSV2': 0.936, 'CrowS-Pairs': 0.553125, 'WinoBias Type1 Dev': 0.5732323232323232, 'WinoBias Type1 Test': 0.5631313131313131, 'WinoBias Type2 Dev': 0.5909090909090909, 'WinoBias Type2 Test': 0.6287878787878788, 'model': 'gpt2_attn_heads_cma_top10', 'seed': '3', 'Professions': 0.8225108225108225}
{'Professions': 0.7788272333726879, 'model': 'gpt2_acdc', 'seed': '1'}
{'LM Score': 90.22571470397557, 'SS Score': 61.549092936049455, 'ICAT': 69.38521141722161, 'BLiMP': 0.7631, 'BLiMP AGA': 0.969, 'BLiMP ISV1': 0.881, 'BLiMP ISV2': 0.865, 'BLiMP RSV1': 0.88, 'BLiMP RSV2': 0.89, 'CrowS-Pairs': 0.584375, 'WinoBias Type1 Dev': 0.5909090909090909, 'WinoBias Type1 Test': 0.5580808080808081, 'WinoBias Type2 Dev': 0.5934343434343434, 'WinoBias Type2 Test': 0.6237373737373737, 'model': 'gpt2_acdc', 'seed': '1'}
{'LM Score': 90.22571470397557, 'SS Score': 61.549092936049455, 'ICAT': 69.38521141722161, 'BLiMP': 0.7631, 'BLiMP AGA': 0.969, 'BLiMP ISV1': 0.881, 'BLiMP ISV2': 0.865, 'BLiMP RSV1': 0.88, 'BLiMP RSV2': 0.89, 'CrowS-Pairs': 0.584375, 'WinoBias Type1 Dev': 0.5909090909090909, 'WinoBias Type1 Test': 0.5580808080808081, 'WinoBias Type2 Dev': 0.5934343434343434, 'WinoBias Type2 Test': 0.6237373737373737, 'model': 'gpt2_acdc', 'seed': '1', 'Professions': 0.7788272333726879}
{'Professions': 0.8089334907516725, 'model': 'gpt2_attn_heads_dm_top10', 'seed': '1'}
{'LM Score': 87.06991124817213, 'SS Score': 62.081751742621314, 'ICAT': 66.0307702091224, 'BLiMP': 0.7759, 'BLiMP AGA': 0.955, 'BLiMP ISV1': 0.895, 'BLiMP ISV2': 0.863, 'BLiMP RSV1': 0.899, 'BLiMP RSV2': 0.936, 'CrowS-Pairs': 0.553125, 'WinoBias Type1 Dev': 0.5757575757575758, 'WinoBias Type1 Test': 0.5732323232323232, 'WinoBias Type2 Dev': 0.5808080808080808, 'WinoBias Type2 Test': 0.6287878787878788, 'model': 'gpt2_attn_heads_dm_top10', 'seed': '1'}
{'LM Score': 87.06991124817213, 'SS Score': 62.081751742621314, 'ICAT': 66.0307702091224, 'BLiMP': 0.7759, 'BLiMP AGA': 0.955, 'BLiMP ISV1': 0.895, 'BLiMP ISV2': 0.863, 'BLiMP RSV1': 0.899, 'BLiMP RSV2': 0.936, 'CrowS-Pairs': 0.553125, 'WinoBias Type1 Dev': 0.5757575757575758, 'WinoBias Type1 Test': 0.5732323232323232, 'WinoBias Type2 Dev': 0.5808080808080808, 'WinoBias Type2 Test': 0.6287878787878788, 'model': 'gpt2_attn_heads_dm_top10', 'seed': '1', 'Professions': 0.8089334907516725}
{'Professions': 0.8305785123966942, 'model': 'gpt2_attn_heads_cma_top10', 'seed': '2'}
{'LM Score': 87.47462818984557, 'SS Score': 61.590071924854534, 'ICAT': 67.19788354344121, 'BLiMP': 0.7749, 'BLiMP AGA': 0.957, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.87, 'BLiMP RSV1': 0.903, 'BLiMP RSV2': 0.933, 'CrowS-Pairs': 0.55, 'WinoBias Type1 Dev': 0.5909090909090909, 'WinoBias Type1 Test': 0.553030303030303, 'WinoBias Type2 Dev': 0.5959595959595959, 'WinoBias Type2 Test': 0.6287878787878788, 'model': 'gpt2_attn_heads_cma_top10', 'seed': '2'}
{'LM Score': 87.47462818984557, 'SS Score': 61.590071924854534, 'ICAT': 67.19788354344121, 'BLiMP': 0.7749, 'BLiMP AGA': 0.957, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.87, 'BLiMP RSV1': 0.903, 'BLiMP RSV2': 0.933, 'CrowS-Pairs': 0.55, 'WinoBias Type1 Dev': 0.5909090909090909, 'WinoBias Type1 Test': 0.553030303030303, 'WinoBias Type2 Dev': 0.5959595959595959, 'WinoBias Type2 Test': 0.6287878787878788, 'model': 'gpt2_attn_heads_cma_top10', 'seed': '2', 'Professions': 0.8305785123966942}
{'Professions': 0.8227075954348682, 'model': 'gpt2_attn_heads_acdc', 'seed': '3'}
{'LM Score': 87.82597555423642, 'SS Score': 62.02932269019226, 'ICAT': 66.6962355437795, 'BLiMP': 0.7695, 'BLiMP AGA': 0.952, 'BLiMP ISV1': 0.895, 'BLiMP ISV2': 0.865, 'BLiMP RSV1': 0.896, 'BLiMP RSV2': 0.936, 'CrowS-Pairs': 0.553125, 'WinoBias Type1 Dev': 0.5707070707070707, 'WinoBias Type1 Test': 0.5631313131313131, 'WinoBias Type2 Dev': 0.5909090909090909, 'WinoBias Type2 Test': 0.6287878787878788, 'model': 'gpt2_attn_heads_acdc', 'seed': '3'}
{'LM Score': 87.82597555423642, 'SS Score': 62.02932269019226, 'ICAT': 66.6962355437795, 'BLiMP': 0.7695, 'BLiMP AGA': 0.952, 'BLiMP ISV1': 0.895, 'BLiMP ISV2': 0.865, 'BLiMP RSV1': 0.896, 'BLiMP RSV2': 0.936, 'CrowS-Pairs': 0.553125, 'WinoBias Type1 Dev': 0.5707070707070707, 'WinoBias Type1 Test': 0.5631313131313131, 'WinoBias Type2 Dev': 0.5909090909090909, 'WinoBias Type2 Test': 0.6287878787878788, 'model': 'gpt2_attn_heads_acdc', 'seed': '3', 'Professions': 0.8227075954348682}
{'Professions': 0.8242817788272334, 'model': 'gpt2_acdc', 'seed': '2'}
{'LM Score': 87.78926468056903, 'SS Score': 59.5827692436388, 'ICAT': 70.96397937051657, 'BLiMP': 0.7606, 'BLiMP AGA': 0.959, 'BLiMP ISV1': 0.889, 'BLiMP ISV2': 0.851, 'BLiMP RSV1': 0.899, 'BLiMP RSV2': 0.87, 'CrowS-Pairs': 0.571875, 'WinoBias Type1 Dev': 0.601010101010101, 'WinoBias Type1 Test': 0.5555555555555556, 'WinoBias Type2 Dev': 0.5959595959595959, 'WinoBias Type2 Test': 0.6136363636363636, 'model': 'gpt2_acdc', 'seed': '2'}
{'LM Score': 87.78926468056903, 'SS Score': 59.5827692436388, 'ICAT': 70.96397937051657, 'BLiMP': 0.7606, 'BLiMP AGA': 0.959, 'BLiMP ISV1': 0.889, 'BLiMP ISV2': 0.851, 'BLiMP RSV1': 0.899, 'BLiMP RSV2': 0.87, 'CrowS-Pairs': 0.571875, 'WinoBias Type1 Dev': 0.601010101010101, 'WinoBias Type1 Test': 0.5555555555555556, 'WinoBias Type2 Dev': 0.5959595959595959, 'WinoBias Type2 Test': 0.6136363636363636, 'model': 'gpt2_acdc', 'seed': '2', 'Professions': 0.8242817788272334}
{'Professions': 0.8138528138528138, 'model': 'gpt2_attn_layers', 'seed': '2'}
{'LM Score': 87.0873105155714, 'SS Score': 61.85159301246257, 'ICAT': 66.4448432999613, 'BLiMP': 0.7712, 'BLiMP AGA': 0.945, 'BLiMP ISV1': 0.895, 'BLiMP ISV2': 0.863, 'BLiMP RSV1': 0.903, 'BLiMP RSV2': 0.944, 'CrowS-Pairs': 0.584375, 'WinoBias Type1 Dev': 0.5782828282828283, 'WinoBias Type1 Test': 0.5454545454545454, 'WinoBias Type2 Dev': 0.6161616161616161, 'WinoBias Type2 Test': 0.5934343434343434, 'model': 'gpt2_attn_layers', 'seed': '2'}
{'LM Score': 87.0873105155714, 'SS Score': 61.85159301246257, 'ICAT': 66.4448432999613, 'BLiMP': 0.7712, 'BLiMP AGA': 0.945, 'BLiMP ISV1': 0.895, 'BLiMP ISV2': 0.863, 'BLiMP RSV1': 0.903, 'BLiMP RSV2': 0.944, 'CrowS-Pairs': 0.584375, 'WinoBias Type1 Dev': 0.5782828282828283, 'WinoBias Type1 Test': 0.5454545454545454, 'WinoBias Type2 Dev': 0.6161616161616161, 'WinoBias Type2 Test': 0.5934343434343434, 'model': 'gpt2_attn_layers', 'seed': '2', 'Professions': 0.8138528138528138}
{'Professions': 0.8144431326249508, 'model': 'gpt2_attn_layers', 'seed': '5'}
{'LM Score': 87.71828324654412, 'SS Score': 61.406612067481625, 'ICAT': 67.70691468216809, 'BLiMP': 0.7692, 'BLiMP AGA': 0.948, 'BLiMP ISV1': 0.896, 'BLiMP ISV2': 0.861, 'BLiMP RSV1': 0.902, 'BLiMP RSV2': 0.942, 'CrowS-Pairs': 0.578125, 'WinoBias Type1 Dev': 0.547979797979798, 'WinoBias Type1 Test': 0.5404040404040404, 'WinoBias Type2 Dev': 0.5833333333333334, 'WinoBias Type2 Test': 0.5808080808080808, 'model': 'gpt2_attn_layers', 'seed': '5'}
{'LM Score': 87.71828324654412, 'SS Score': 61.406612067481625, 'ICAT': 67.70691468216809, 'BLiMP': 0.7692, 'BLiMP AGA': 0.948, 'BLiMP ISV1': 0.896, 'BLiMP ISV2': 0.861, 'BLiMP RSV1': 0.902, 'BLiMP RSV2': 0.942, 'CrowS-Pairs': 0.578125, 'WinoBias Type1 Dev': 0.547979797979798, 'WinoBias Type1 Test': 0.5404040404040404, 'WinoBias Type2 Dev': 0.5833333333333334, 'WinoBias Type2 Test': 0.5808080808080808, 'model': 'gpt2_attn_layers', 'seed': '5', 'Professions': 0.8144431326249508}
{'Professions': 0.8364817001180638, 'model': 'gpt2_attn_layers_all', 'seed': '5'}
{'LM Score': 87.59762427588514, 'SS Score': 64.17076417945984, 'ICAT': 62.771118749995246, 'BLiMP': 0.7824, 'BLiMP AGA': 0.974, 'BLiMP ISV1': 0.877, 'BLiMP ISV2': 0.842, 'BLiMP RSV1': 0.913, 'BLiMP RSV2': 0.887, 'CrowS-Pairs': 0.60625, 'WinoBias Type1 Dev': 0.5984848484848485, 'WinoBias Type1 Test': 0.5505050505050505, 'WinoBias Type2 Dev': 0.6237373737373737, 'WinoBias Type2 Test': 0.6111111111111112, 'model': 'gpt2_attn_layers_all', 'seed': '5'}
{'LM Score': 87.59762427588514, 'SS Score': 64.17076417945984, 'ICAT': 62.771118749995246, 'BLiMP': 0.7824, 'BLiMP AGA': 0.974, 'BLiMP ISV1': 0.877, 'BLiMP ISV2': 0.842, 'BLiMP RSV1': 0.913, 'BLiMP RSV2': 0.887, 'CrowS-Pairs': 0.60625, 'WinoBias Type1 Dev': 0.5984848484848485, 'WinoBias Type1 Test': 0.5505050505050505, 'WinoBias Type2 Dev': 0.6237373737373737, 'WinoBias Type2 Test': 0.6111111111111112, 'model': 'gpt2_attn_layers_all', 'seed': '5', 'Professions': 0.8364817001180638}
{'Professions': 0.8073593073593074, 'model': 'gpt2_attn_heads_dm_top10', 'seed': '2'}
{'LM Score': 87.85818167339906, 'SS Score': 61.76225642312598, 'ICAT': 67.1899724391569, 'BLiMP': 0.7782, 'BLiMP AGA': 0.949, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.864, 'BLiMP RSV1': 0.895, 'BLiMP RSV2': 0.935, 'CrowS-Pairs': 0.546875, 'WinoBias Type1 Dev': 0.5757575757575758, 'WinoBias Type1 Test': 0.5656565656565656, 'WinoBias Type2 Dev': 0.6136363636363636, 'WinoBias Type2 Test': 0.6388888888888888, 'model': 'gpt2_attn_heads_dm_top10', 'seed': '2'}
{'LM Score': 87.85818167339906, 'SS Score': 61.76225642312598, 'ICAT': 67.1899724391569, 'BLiMP': 0.7782, 'BLiMP AGA': 0.949, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.864, 'BLiMP RSV1': 0.895, 'BLiMP RSV2': 0.935, 'CrowS-Pairs': 0.546875, 'WinoBias Type1 Dev': 0.5757575757575758, 'WinoBias Type1 Test': 0.5656565656565656, 'WinoBias Type2 Dev': 0.6136363636363636, 'WinoBias Type2 Test': 0.6388888888888888, 'model': 'gpt2_attn_heads_dm_top10', 'seed': '2', 'Professions': 0.8073593073593074}
{'Professions': 0.8156237701692247, 'model': 'gpt2_all', 'seed': '2'}
{'LM Score': 88.03307031133119, 'SS Score': 61.05786081873039, 'ICAT': 68.56392153236705, 'BLiMP': 0.7639, 'BLiMP AGA': 0.969, 'BLiMP ISV1': 0.875, 'BLiMP ISV2': 0.837, 'BLiMP RSV1': 0.897, 'BLiMP RSV2': 0.826, 'CrowS-Pairs': 0.5625, 'WinoBias Type1 Dev': 0.6035353535353535, 'WinoBias Type1 Test': 0.5328282828282829, 'WinoBias Type2 Dev': 0.5858585858585859, 'WinoBias Type2 Test': 0.601010101010101, 'model': 'gpt2_all', 'seed': '2'}
{'LM Score': 88.03307031133119, 'SS Score': 61.05786081873039, 'ICAT': 68.56392153236705, 'BLiMP': 0.7639, 'BLiMP AGA': 0.969, 'BLiMP ISV1': 0.875, 'BLiMP ISV2': 0.837, 'BLiMP RSV1': 0.897, 'BLiMP RSV2': 0.826, 'CrowS-Pairs': 0.5625, 'WinoBias Type1 Dev': 0.6035353535353535, 'WinoBias Type1 Test': 0.5328282828282829, 'WinoBias Type2 Dev': 0.5858585858585859, 'WinoBias Type2 Test': 0.601010101010101, 'model': 'gpt2_all', 'seed': '2', 'Professions': 0.8156237701692247}
{'Professions': 0.8522235340417159, 'model': 'gpt2_acdc', 'seed': '4'}
{'LM Score': 87.88157180983268, 'SS Score': 58.54287435591783, 'ICAT': 72.86634728639326, 'BLiMP': 0.7574, 'BLiMP AGA': 0.964, 'BLiMP ISV1': 0.879, 'BLiMP ISV2': 0.858, 'BLiMP RSV1': 0.897, 'BLiMP RSV2': 0.899, 'CrowS-Pairs': 0.590625, 'WinoBias Type1 Dev': 0.6060606060606061, 'WinoBias Type1 Test': 0.5429292929292929, 'WinoBias Type2 Dev': 0.5909090909090909, 'WinoBias Type2 Test': 0.6186868686868687, 'model': 'gpt2_acdc', 'seed': '4'}
{'LM Score': 87.88157180983268, 'SS Score': 58.54287435591783, 'ICAT': 72.86634728639326, 'BLiMP': 0.7574, 'BLiMP AGA': 0.964, 'BLiMP ISV1': 0.879, 'BLiMP ISV2': 0.858, 'BLiMP RSV1': 0.897, 'BLiMP RSV2': 0.899, 'CrowS-Pairs': 0.590625, 'WinoBias Type1 Dev': 0.6060606060606061, 'WinoBias Type1 Test': 0.5429292929292929, 'WinoBias Type2 Dev': 0.5909090909090909, 'WinoBias Type2 Test': 0.6186868686868687, 'model': 'gpt2_acdc', 'seed': '4', 'Professions': 0.8522235340417159}
{'Professions': 0.7922077922077922, 'model': 'gpt2_all', 'seed': '1'}
{'LM Score': 88.77754250580338, 'SS Score': 62.00141726228683, 'ICAT': 67.46841588315236, 'BLiMP': 0.7669, 'BLiMP AGA': 0.965, 'BLiMP ISV1': 0.876, 'BLiMP ISV2': 0.849, 'BLiMP RSV1': 0.897, 'BLiMP RSV2': 0.853, 'CrowS-Pairs': 0.603125, 'WinoBias Type1 Dev': 0.5934343434343434, 'WinoBias Type1 Test': 0.5580808080808081, 'WinoBias Type2 Dev': 0.6085858585858586, 'WinoBias Type2 Test': 0.6212121212121212, 'model': 'gpt2_all', 'seed': '1'}
{'LM Score': 88.77754250580338, 'SS Score': 62.00141726228683, 'ICAT': 67.46841588315236, 'BLiMP': 0.7669, 'BLiMP AGA': 0.965, 'BLiMP ISV1': 0.876, 'BLiMP ISV2': 0.849, 'BLiMP RSV1': 0.897, 'BLiMP RSV2': 0.853, 'CrowS-Pairs': 0.603125, 'WinoBias Type1 Dev': 0.5934343434343434, 'WinoBias Type1 Test': 0.5580808080808081, 'WinoBias Type2 Dev': 0.6085858585858586, 'WinoBias Type2 Test': 0.6212121212121212, 'model': 'gpt2_all', 'seed': '1', 'Professions': 0.7922077922077922}
{'Professions': 0.8317591499409681, 'model': 'gpt2_attn_layers_all', 'seed': '3'}
{'LM Score': 88.15441321963061, 'SS Score': 65.4795613404309, 'ICAT': 60.86258028237131, 'BLiMP': 0.7815, 'BLiMP AGA': 0.961, 'BLiMP ISV1': 0.876, 'BLiMP ISV2': 0.853, 'BLiMP RSV1': 0.917, 'BLiMP RSV2': 0.896, 'CrowS-Pairs': 0.575, 'WinoBias Type1 Dev': 0.5934343434343434, 'WinoBias Type1 Test': 0.553030303030303, 'WinoBias Type2 Dev': 0.6363636363636364, 'WinoBias Type2 Test': 0.6313131313131313, 'model': 'gpt2_attn_layers_all', 'seed': '3'}
{'LM Score': 88.15441321963061, 'SS Score': 65.4795613404309, 'ICAT': 60.86258028237131, 'BLiMP': 0.7815, 'BLiMP AGA': 0.961, 'BLiMP ISV1': 0.876, 'BLiMP ISV2': 0.853, 'BLiMP RSV1': 0.917, 'BLiMP RSV2': 0.896, 'CrowS-Pairs': 0.575, 'WinoBias Type1 Dev': 0.5934343434343434, 'WinoBias Type1 Test': 0.553030303030303, 'WinoBias Type2 Dev': 0.6363636363636364, 'WinoBias Type2 Test': 0.6313131313131313, 'model': 'gpt2_attn_layers_all', 'seed': '3', 'Professions': 0.8317591499409681}
{'Professions': 0.8341204250295159, 'model': 'gpt2_attn_layers_all', 'seed': '1'}
{'LM Score': 87.71412371847154, 'SS Score': 65.56124036993603, 'ICAT': 60.415312458042685, 'BLiMP': 0.7828, 'BLiMP AGA': 0.964, 'BLiMP ISV1': 0.878, 'BLiMP ISV2': 0.866, 'BLiMP RSV1': 0.914, 'BLiMP RSV2': 0.903, 'CrowS-Pairs': 0.584375, 'WinoBias Type1 Dev': 0.5732323232323232, 'WinoBias Type1 Test': 0.547979797979798, 'WinoBias Type2 Dev': 0.6237373737373737, 'WinoBias Type2 Test': 0.6060606060606061, 'model': 'gpt2_attn_layers_all', 'seed': '1'}
{'LM Score': 87.71412371847154, 'SS Score': 65.56124036993603, 'ICAT': 60.415312458042685, 'BLiMP': 0.7828, 'BLiMP AGA': 0.964, 'BLiMP ISV1': 0.878, 'BLiMP ISV2': 0.866, 'BLiMP RSV1': 0.914, 'BLiMP RSV2': 0.903, 'CrowS-Pairs': 0.584375, 'WinoBias Type1 Dev': 0.5732323232323232, 'WinoBias Type1 Test': 0.547979797979798, 'WinoBias Type2 Dev': 0.6237373737373737, 'WinoBias Type2 Test': 0.6060606060606061, 'model': 'gpt2_attn_layers_all', 'seed': '1', 'Professions': 0.8341204250295159}
{'Professions': 0.8211334120425029, 'model': 'gpt2_attn_heads_dm_top10', 'seed': '3'}
{'LM Score': 86.70011067837154, 'SS Score': 60.92675858762816, 'ICAT': 67.75308710030738, 'BLiMP': 0.7774, 'BLiMP AGA': 0.952, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.868, 'BLiMP RSV1': 0.897, 'BLiMP RSV2': 0.937, 'CrowS-Pairs': 0.553125, 'WinoBias Type1 Dev': 0.5707070707070707, 'WinoBias Type1 Test': 0.5656565656565656, 'WinoBias Type2 Dev': 0.5984848484848485, 'WinoBias Type2 Test': 0.6313131313131313, 'model': 'gpt2_attn_heads_dm_top10', 'seed': '3'}
{'LM Score': 86.70011067837154, 'SS Score': 60.92675858762816, 'ICAT': 67.75308710030738, 'BLiMP': 0.7774, 'BLiMP AGA': 0.952, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.868, 'BLiMP RSV1': 0.897, 'BLiMP RSV2': 0.937, 'CrowS-Pairs': 0.553125, 'WinoBias Type1 Dev': 0.5707070707070707, 'WinoBias Type1 Test': 0.5656565656565656, 'WinoBias Type2 Dev': 0.5984848484848485, 'WinoBias Type2 Test': 0.6313131313131313, 'model': 'gpt2_attn_heads_dm_top10', 'seed': '3', 'Professions': 0.8211334120425029}
{'Professions': 0.8327430145611964, 'model': 'gpt2_attn_heads_cma_top10', 'seed': '5'}
{'LM Score': 86.87373632808416, 'SS Score': 61.56635972722929, 'ICAT': 66.77747862370238, 'BLiMP': 0.7767, 'BLiMP AGA': 0.964, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.87, 'BLiMP RSV1': 0.9, 'BLiMP RSV2': 0.937, 'CrowS-Pairs': 0.553125, 'WinoBias Type1 Dev': 0.5681818181818182, 'WinoBias Type1 Test': 0.5505050505050505, 'WinoBias Type2 Dev': 0.6287878787878788, 'WinoBias Type2 Test': 0.6338383838383839, 'model': 'gpt2_attn_heads_cma_top10', 'seed': '5'}
{'LM Score': 86.87373632808416, 'SS Score': 61.56635972722929, 'ICAT': 66.77747862370238, 'BLiMP': 0.7767, 'BLiMP AGA': 0.964, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.87, 'BLiMP RSV1': 0.9, 'BLiMP RSV2': 0.937, 'CrowS-Pairs': 0.553125, 'WinoBias Type1 Dev': 0.5681818181818182, 'WinoBias Type1 Test': 0.5505050505050505, 'WinoBias Type2 Dev': 0.6287878787878788, 'WinoBias Type2 Test': 0.6338383838383839, 'model': 'gpt2_attn_heads_cma_top10', 'seed': '5', 'Professions': 0.8327430145611964}
{'Professions': 0.8134592680047226, 'model': 'gpt2_attn_heads_cma_top10', 'seed': '1'}
{'LM Score': 87.38018430844518, 'SS Score': 63.19642853121114, 'ICAT': 64.3180571630361, 'BLiMP': 0.7702, 'BLiMP AGA': 0.958, 'BLiMP ISV1': 0.897, 'BLiMP ISV2': 0.871, 'BLiMP RSV1': 0.906, 'BLiMP RSV2': 0.936, 'CrowS-Pairs': 0.56875, 'WinoBias Type1 Dev': 0.5782828282828283, 'WinoBias Type1 Test': 0.553030303030303, 'WinoBias Type2 Dev': 0.5959595959595959, 'WinoBias Type2 Test': 0.6414141414141414, 'model': 'gpt2_attn_heads_cma_top10', 'seed': '1'}
{'LM Score': 87.38018430844518, 'SS Score': 63.19642853121114, 'ICAT': 64.3180571630361, 'BLiMP': 0.7702, 'BLiMP AGA': 0.958, 'BLiMP ISV1': 0.897, 'BLiMP ISV2': 0.871, 'BLiMP RSV1': 0.906, 'BLiMP RSV2': 0.936, 'CrowS-Pairs': 0.56875, 'WinoBias Type1 Dev': 0.5782828282828283, 'WinoBias Type1 Test': 0.553030303030303, 'WinoBias Type2 Dev': 0.5959595959595959, 'WinoBias Type2 Test': 0.6414141414141414, 'model': 'gpt2_attn_heads_cma_top10', 'seed': '1', 'Professions': 0.8134592680047226}
{'Professions': 0.8164108618654073, 'model': 'gpt2_attn_heads_cma_top10', 'seed': '4'}
{'LM Score': 86.89184857010945, 'SS Score': 61.76967235662888, 'ICAT': 66.43807680746944, 'BLiMP': 0.7729, 'BLiMP AGA': 0.954, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.871, 'BLiMP RSV1': 0.901, 'BLiMP RSV2': 0.925, 'CrowS-Pairs': 0.565625, 'WinoBias Type1 Dev': 0.601010101010101, 'WinoBias Type1 Test': 0.5429292929292929, 'WinoBias Type2 Dev': 0.601010101010101, 'WinoBias Type2 Test': 0.6287878787878788, 'model': 'gpt2_attn_heads_cma_top10', 'seed': '4'}
{'LM Score': 86.89184857010945, 'SS Score': 61.76967235662888, 'ICAT': 66.43807680746944, 'BLiMP': 0.7729, 'BLiMP AGA': 0.954, 'BLiMP ISV1': 0.899, 'BLiMP ISV2': 0.871, 'BLiMP RSV1': 0.901, 'BLiMP RSV2': 0.925, 'CrowS-Pairs': 0.565625, 'WinoBias Type1 Dev': 0.601010101010101, 'WinoBias Type1 Test': 0.5429292929292929, 'WinoBias Type2 Dev': 0.601010101010101, 'WinoBias Type2 Test': 0.6287878787878788, 'model': 'gpt2_attn_heads_cma_top10', 'seed': '4', 'Professions': 0.8164108618654073}
{'Professions': 0.8138528138528138, 'model': 'gpt2_attn_heads_acdc', 'seed': '1'}
{'LM Score': 87.38018430844518, 'SS Score': 63.19642853121114, 'ICAT': 64.3180571630361, 'BLiMP': 0.7702, 'BLiMP AGA': 0.958, 'BLiMP ISV1': 0.897, 'BLiMP ISV2': 0.871, 'BLiMP RSV1': 0.906, 'BLiMP RSV2': 0.936, 'CrowS-Pairs': 0.56875, 'WinoBias Type1 Dev': 0.5782828282828283, 'WinoBias Type1 Test': 0.553030303030303, 'WinoBias Type2 Dev': 0.5959595959595959, 'WinoBias Type2 Test': 0.6414141414141414, 'model': 'gpt2_attn_heads_acdc', 'seed': '1'}
{'LM Score': 87.38018430844518, 'SS Score': 63.19642853121114, 'ICAT': 64.3180571630361, 'BLiMP': 0.7702, 'BLiMP AGA': 0.958, 'BLiMP ISV1': 0.897, 'BLiMP ISV2': 0.871, 'BLiMP RSV1': 0.906, 'BLiMP RSV2': 0.936, 'CrowS-Pairs': 0.56875, 'WinoBias Type1 Dev': 0.5782828282828283, 'WinoBias Type1 Test': 0.553030303030303, 'WinoBias Type2 Dev': 0.5959595959595959, 'WinoBias Type2 Test': 0.6414141414141414, 'model': 'gpt2_attn_heads_acdc', 'seed': '1', 'Professions': 0.8138528138528138}
{'Professions': 0.8077528532073986, 'model': 'gpt2_attn_layers', 'seed': '1'}
{'LM Score': 87.44505148635585, 'SS Score': 62.58867074954031, 'ICAT': 65.42871224958915, 'BLiMP': 0.769, 'BLiMP AGA': 0.942, 'BLiMP ISV1': 0.896, 'BLiMP ISV2': 0.867, 'BLiMP RSV1': 0.902, 'BLiMP RSV2': 0.942, 'CrowS-Pairs': 0.584375, 'WinoBias Type1 Dev': 0.5631313131313131, 'WinoBias Type1 Test': 0.5681818181818182, 'WinoBias Type2 Dev': 0.6085858585858586, 'WinoBias Type2 Test': 0.6035353535353535, 'model': 'gpt2_attn_layers', 'seed': '1'}
{'LM Score': 87.44505148635585, 'SS Score': 62.58867074954031, 'ICAT': 65.42871224958915, 'BLiMP': 0.769, 'BLiMP AGA': 0.942, 'BLiMP ISV1': 0.896, 'BLiMP ISV2': 0.867, 'BLiMP RSV1': 0.902, 'BLiMP RSV2': 0.942, 'CrowS-Pairs': 0.584375, 'WinoBias Type1 Dev': 0.5631313131313131, 'WinoBias Type1 Test': 0.5681818181818182, 'WinoBias Type2 Dev': 0.6085858585858586, 'WinoBias Type2 Test': 0.6035353535353535, 'model': 'gpt2_attn_layers', 'seed': '1', 'Professions': 0.8077528532073986}
{'Professions': 0.8384494293585203, 'model': 'gpt2_random', 'seed': '2'}
{'LM Score': 87.04533638664074, 'SS Score': 61.434084594954165, 'ICAT': 67.1396615898189, 'BLiMP': 0.7758, 'BLiMP AGA': 0.962, 'BLiMP ISV1': 0.888, 'BLiMP ISV2': 0.864, 'BLiMP RSV1': 0.892, 'BLiMP RSV2': 0.91, 'CrowS-Pairs': 0.590625, 'WinoBias Type1 Dev': 0.5808080808080808, 'WinoBias Type1 Test': 0.5454545454545454, 'WinoBias Type2 Dev': 0.601010101010101, 'WinoBias Type2 Test': 0.6237373737373737, 'model': 'gpt2_random', 'seed': '2'}
{'LM Score': 87.04533638664074, 'SS Score': 61.434084594954165, 'ICAT': 67.1396615898189, 'BLiMP': 0.7758, 'BLiMP AGA': 0.962, 'BLiMP ISV1': 0.888, 'BLiMP ISV2': 0.864, 'BLiMP RSV1': 0.892, 'BLiMP RSV2': 0.91, 'CrowS-Pairs': 0.590625, 'WinoBias Type1 Dev': 0.5808080808080808, 'WinoBias Type1 Test': 0.5454545454545454, 'WinoBias Type2 Dev': 0.601010101010101, 'WinoBias Type2 Test': 0.6237373737373737, 'model': 'gpt2_random', 'seed': '2', 'Professions': 0.8384494293585203}

JOB STATISTICS
==============
Job ID: 3599647
Cluster: snellius
User/Group: abhijith/abhijith
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:58:56
CPU Efficiency: 5.52% of 17:47:42 core-walltime
Job Wall-clock time: 00:59:19
Memory Utilized: 3.15 GB
Memory Efficiency: 2.63% of 120.00 GB
